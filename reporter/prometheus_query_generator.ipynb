{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-09T15:00:21.785151Z",
     "start_time": "2024-12-09T15:00:21.782496Z"
    }
   },
   "source": [
    "# This class represent function to calculate energy consumption of running pipelines\n",
    "#curl -s 'http://localhost:9090/api/v1/label/__name__/values' | jq '.data[] | select(. | contains(\"kepler\"))'\n",
    "\n",
    "#https://www.run.ai/guides/kubernetes-architecture/kubeflow-pipelines-the-basics-and-a-quick-tutorial.     KUBEFLOW_ARCH\n",
    "#https://medium.com/@ketangangal98/introduction-d07e3aca35ac.         KUBEFLOW_ARCH\n",
    "#http://localhost:9102/metrics\n",
    "#http://localhost:9090/graph?g0.expr=%7Bnamespace%3D%22kubeflow%22%7D%20%3E%200&g0.tab=1&g0.display_mode=lines&g0.show_exemplars=0&g0.range_input=1h\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:00:21.803185Z",
     "start_time": "2024-12-09T15:00:21.795386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from kfp import Client\n",
    "\n",
    "def get_pipelines_cpu_memory_usage(pipeline_config_path: str):\n",
    "    # Load the pipeline configuration from the specified YAML file\n",
    "    with open(pipeline_config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    # Extract necessary values from the configuration\n",
    "    namespace = config['Deployment']['namespace']\n",
    "    prometheus_url = config['Deployment']['prometheusURL']\n",
    "    label_key = 'pipeline/runid'  # Specify the label key for querying metrics\n",
    "\n",
    "    # Initialize the Kubeflow Pipelines client\n",
    "    kfp_client = Client()\n",
    "    pipelines = kfp_client.list_pipelines()\n",
    "    print(f\"pipeline size: {pipelines.total_size}\")\n",
    "    total_usage_data = []\n",
    "\n",
    "    # Iterate over each pipeline\n",
    "    for pipeline in pipelines.pipelines:\n",
    "        print(f\"Processing pipeline: {pipeline.display_name}\")\n",
    "        # filter=json.dumps({\n",
    "        #                 \"predicates\": [{\n",
    "        #                     \"operation\": \"EQUALS\",\n",
    "        #                     \"key\": \"runs.runs.pipeline_spec.pipeline_id\",\n",
    "        #                     \"stringValue\": pipeline.pipeline_id,\n",
    "        #                 }]\n",
    "        #             })\n",
    "        # Get runs for the current pipeline\n",
    "        runs = kfp_client.list_runs()\n",
    "\n",
    "\n",
    "        # Iterate over each run of the pipeline\n",
    "        for run in runs.runs:\n",
    "            # Retrieve CPU and memory usage metrics\n",
    "            total_cpu_usage_value = get_total_cpu_usage_metrics(label_key, run.run_id, namespace, prometheus_url)\n",
    "            total_memory_usage_value = get_total_mem_usage_metrics(label_key, run.run_id, namespace, prometheus_url)\n",
    "            total_joules = get_total_container_joules(label_key, run.run_id, namespace, prometheus_url)\n",
    "\n",
    "            # Append the results to the usage data list\n",
    "            total_usage_data.append({\n",
    "                'pipeline_name': pipeline.display_name,\n",
    "                'pipeline_id': pipeline.pipeline_id,\n",
    "                'run_id': run.run_id,\n",
    "                'total_memory_usage': total_memory_usage_value,\n",
    "                'total_cpu_usage': total_cpu_usage_value,\n",
    "                'total_joules' : total_joules\n",
    "            })\n",
    "    print(total_usage_data)\n",
    "    # Return the collected data as a DataFrame\n",
    "    return pd.DataFrame(total_usage_data)\n",
    "\n"
   ],
   "id": "ec2a5f67adbe8d25",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:00:21.820658Z",
     "start_time": "2024-12-09T15:00:21.817456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def get_cpu_usage_metrics_per_pod(label_key: str, label_value: str, namespace: str, prometheus_url: str):\n",
    "    # Construct the Prometheus query for CPU usage per pod with the specified label\n",
    "    query = f'rate(kepler_container_core_joules_total{{namespace=\"{namespace}\", \"{label_key}\"=\"{label_value}\"}}[5m])'\n",
    "\n",
    "    # Query Prometheus for the CPU consumption metrics\n",
    "    response = requests.get(f\"{prometheus_url}/api/v1/query\", params={'query': query})\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        metrics_data = response.json()\n",
    "        results = metrics_data['data']['result']\n",
    "        if results:\n",
    "            pod_cpu_usage = []\n",
    "            for result in results:\n",
    "                pod_name = result['metric'].get('pod')  # Extract pod name from the metric\n",
    "                cpu_usage = float(result['value'][1])  # Get the CPU usage value for the pod\n",
    "                pod_cpu_usage.append({'pod_name': pod_name, 'cpu_usage': cpu_usage})\n",
    "            \n",
    "            # Convert to a pandas DataFrame\n",
    "            df = pd.DataFrame(pod_cpu_usage)\n",
    "            return df\n",
    "        else:\n",
    "            # Return an empty DataFrame if no results\n",
    "            return pd.DataFrame(columns=['pod_name', 'cpu_usage'])\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n"
   ],
   "id": "5d8faa81c14aba46",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:00:21.828882Z",
     "start_time": "2024-12-09T15:00:21.826474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "def get_total_cpu_usage_metrics(label_key:str,label_value:str, namespace:str, prometheus_url:str):\n",
    "\n",
    "   # Construct the Prometheus query for total CPU usage across all pods\n",
    "    query = f'sum(rate(kepler_container_core_joules_total{{namespace=\"{namespace}\", \"{label_key}\"=\"{label_value}\"}}[5m]))'\n",
    "    \n",
    "    # Query Prometheus for the CPU consumption metrics\n",
    "    response = requests.get(f\"{prometheus_url}/api/v1/query\", params={'query': query})\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        metrics_data = response.json()\n",
    "        results = metrics_data['data']['result']\n",
    "        if results:\n",
    "            total_cpu_usage = float(results[0]['value'][1])  # Get the total CPU usage value\n",
    "            return total_cpu_usage\n",
    "        else:\n",
    "            return 0.0 \n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n"
   ],
   "id": "a15d83512c0a6682",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:00:21.837147Z",
     "start_time": "2024-12-09T15:00:21.834209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def get_mem_usage_metrics_per_pod(label_key: str, label_value: str, namespace: str, prometheus_url: str):\n",
    "    # Construct the Prometheus query for memory usage per pod with the specified label\n",
    "    query = f'rate(kepler_container_bpf_cpu_time_ms_total{{namespace=\"{namespace}\", \"{label_key}\"=\"{label_value}\"}}[5m])'\n",
    "\n",
    "    # Query Prometheus for the memory consumption metrics\n",
    "    response = requests.get(f\"{prometheus_url}/api/v1/query\", params={'query': query})\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        metrics_data = response.json()\n",
    "        results = metrics_data['data']['result']\n",
    "        if results:\n",
    "            pod_mem_usage = []\n",
    "            for result in results:\n",
    "                pod_name = result['metric'].get('pod')  # Extract pod name from the metric\n",
    "                mem_usage = float(result['value'][1])  # Get the memory usage value for the pod\n",
    "                pod_mem_usage.append({'pod_name': pod_name, 'mem_usage': mem_usage})\n",
    "            \n",
    "            # Convert to a pandas DataFrame\n",
    "            df = pd.DataFrame(pod_mem_usage)\n",
    "            return df\n",
    "        else:\n",
    "            # Return an empty DataFrame if no results\n",
    "            return pd.DataFrame(columns=['pod_name', 'mem_usage'])\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n"
   ],
   "id": "6567dd86acc0adb0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:00:21.844806Z",
     "start_time": "2024-12-09T15:00:21.842758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "def get_total_mem_usage_metrics(label_key:str,label_value:str, namespace:str, prometheus_url:str):\n",
    "\n",
    "   # query = f'sum(rate(container_memory_usage_bytes{{namespace=\"{namespace}\", {label_key}=\"{label_value}\"}}[5m])) by (pod)'\n",
    "    query = f'sum(rate(kepler_container_bpf_cpu_time_ms_total{{namespace=\"{namespace}\", \"{label_key}\"=\"{label_value}\"}}[5m]))'\n",
    "\n",
    "    response = requests.get(f\"{prometheus_url}/api/v1/query\", params={'query': query})\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        metrics_data = response.json()\n",
    "        results = metrics_data['data']['result']\n",
    "        if results:\n",
    "            total_memory_usage = float(results[0]['value'][1])  # Get the total memory usage value\n",
    "            return total_memory_usage\n",
    "        else:\n",
    "            return 0.0 \n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\") \n",
    "        \n",
    "    #     metrics = [{'pod': result['metric']['pod'], 'memory_usage': float(result['value'][1])} for result in results]\n",
    "    #     return pd.DataFrame(metrics)\n",
    "    # else:\n",
    "    #     raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "    "
   ],
   "id": "b0bdd9e0aa4323d0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:00:21.850866Z",
     "start_time": "2024-12-09T15:00:21.848628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def get_container_joules_metrics_per_pod(label_key: str, label_value: str, namespace: str, prometheus_url: str):\n",
    "    # Construct the Prometheus query for energy usage per pod with the specified label\n",
    "    query = f'rate(kepler_container_joules_total{{namespace=\"{namespace}\", \"{label_key}\"=\"{label_value}\"}}[5m])'\n",
    "\n",
    "    # Query Prometheus for the energy consumption metrics\n",
    "    response = requests.get(f\"{prometheus_url}/api/v1/query\", params={'query': query})\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        metrics_data = response.json()\n",
    "        results = metrics_data['data']['result']\n",
    "        if results:\n",
    "            pod_joules_usage = []\n",
    "            for result in results:\n",
    "                pod_name = result['metric'].get('pod')  # Extract pod name from the metric\n",
    "                joules_usage = float(result['value'][1])  # Get the energy usage value (in joules) for the pod\n",
    "                pod_joules_usage.append({'pod_name': pod_name, 'joules_usage': joules_usage})\n",
    "            \n",
    "            # Convert to a pandas DataFrame\n",
    "            df = pd.DataFrame(pod_joules_usage)\n",
    "            return df\n",
    "        else:\n",
    "            # Return an empty DataFrame if no results\n",
    "            return pd.DataFrame(columns=['pod_name', 'joules_usage'])\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n"
   ],
   "id": "540ce9bfe7e7b1d0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:00:21.856404Z",
     "start_time": "2024-12-09T15:00:21.854531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_total_container_joules(label_key:str,label_value:str, namespace:str, prometheus_url:str):\n",
    "\n",
    "  # query = f'sum(rate(container_memory_usage_bytes{{namespace=\"{namespace}\", {label_key}=\"{label_value}\"}}[5m])) by (pod)'\n",
    "    query = f'sum(rate(kepler_container_joules_total{{namespace=\"{namespace}\", \"{label_key}\"=\"{label_value}\"}}[5m]))'\n",
    "\n",
    "    response = requests.get(f\"{prometheus_url}/api/v1/query\", params={'query': query})\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        metrics_data = response.json()\n",
    "        results = metrics_data['data']['result']\n",
    "        if results:\n",
    "            total_memory_usage = float(results[0]['value'][1])  # Get the total memory usage value\n",
    "            return total_memory_usage\n",
    "        else:\n",
    "            return 0.0 \n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\") \n",
    "        \n",
    "    #     metrics = [{'pod': result['metric']['pod'], 'memory_usage': float(result['value'][1])} for result in results]\n",
    "    #     return pd.DataFrame(metrics)\n",
    "    # else:\n",
    "    #     raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "        "
   ],
   "id": "1889504ea031e71",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:00:21.862630Z",
     "start_time": "2024-12-09T15:00:21.859772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_pipelines_cpu_memory_usage_per_pod(pipeline_config_path: str):\n",
    "    # Load the pipeline configuration from the specified YAML file\n",
    "    with open(pipeline_config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    # Extract necessary values from the configuration\n",
    "    namespace = config['Deployment']['namespace']\n",
    "    prometheus_url = config['Deployment']['prometheusURL']\n",
    "    label_key = 'pipeline/runid'  # Specify the label key for querying metrics\n",
    "\n",
    "    # Initialize the Kubeflow Pipelines client\n",
    "    kfp_client = Client()\n",
    "    pipelines = kfp_client.list_pipelines()\n",
    "    print(f\"Pipeline size: {pipelines.total_size}\")\n",
    "    total_usage_data = []\n",
    "\n",
    "    # Iterate over each pipeline\n",
    "    for pipeline in pipelines.pipelines:\n",
    "        print(f\"Processing pipeline: {pipeline.display_name}\")\n",
    "        # Get runs for the current pipeline\n",
    "        runs = kfp_client.list_runs()\n",
    "\n",
    "        # Iterate over each run of the pipeline\n",
    "        for run in runs.runs:\n",
    "            run_id = run.run_id\n",
    "\n",
    "            # Retrieve CPU, memory, and energy usage metrics for all pods in the run\n",
    "            cpu_metrics_per_pod = get_cpu_usage_metrics_per_pod(label_key, run_id, namespace, prometheus_url)\n",
    "            mem_metrics_per_pod = get_mem_usage_metrics_per_pod(label_key, run_id, namespace, prometheus_url)\n",
    "            joules_metrics_per_pod = get_container_joules_metrics_per_pod(label_key, run_id, namespace, prometheus_url)\n",
    "\n",
    "            # Merge the per-pod metrics into a single DataFrame\n",
    "            pod_metrics = cpu_metrics_per_pod.merge(mem_metrics_per_pod, on='pod_name', how='outer')\n",
    "            pod_metrics = pod_metrics.merge(joules_metrics_per_pod, on='pod_name', how='outer')\n",
    "\n",
    "            # Add metadata columns to the DataFrame\n",
    "            pod_metrics['pipeline_name'] = pipeline.display_name\n",
    "            pod_metrics['pipeline_id'] = pipeline.pipeline_id\n",
    "            pod_metrics['run_id'] = run_id\n",
    "\n",
    "            # Retrieve aggregated metrics for the entire run\n",
    "            total_cpu_usage_value = get_total_cpu_usage_metrics(label_key, run_id, namespace, prometheus_url)\n",
    "            total_memory_usage_value = get_total_mem_usage_metrics(label_key, run_id, namespace, prometheus_url)\n",
    "            total_joules = get_total_container_joules(label_key, run_id, namespace, prometheus_url)\n",
    "\n",
    "            # Add aggregated data as a new row (for summary purposes)\n",
    "            total_usage_data.append({\n",
    "                'pipeline_name': pipeline.display_name,\n",
    "                'pipeline_id': pipeline.pipeline_id,\n",
    "                'run_id': run_id,\n",
    "                'total_memory_usage': total_memory_usage_value,\n",
    "                'total_cpu_usage': total_cpu_usage_value,\n",
    "                'total_joules': total_joules,\n",
    "                'pod_metrics': pod_metrics  # Attach the per-pod DataFrame for further analysis\n",
    "            })\n",
    "\n",
    "    # Convert the aggregated usage data to a DataFrame\n",
    "    total_usage_df = pd.DataFrame(total_usage_data)\n",
    "\n",
    "    # Return the DataFrame containing both aggregated and per-pod data\n",
    "    return total_usage_df\n"
   ],
   "id": "cea15a4bea690aef",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:00:21.867992Z",
     "start_time": "2024-12-09T15:00:21.865880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# draw pandas area plots\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot an area chart for a metric\n",
    "def plot_area_per_pod(output_df: pd.DataFrame, metric: str, title: str, xlabel: str, ylabel: str):\n",
    "    \"\"\"\n",
    "    Plot an area chart for the given metric in the pipeline's per-pod usage data.\n",
    "\n",
    "    :param output_df: DataFrame containing pipeline per-pod usage metrics.\n",
    "    :param metric: The metric to visualize (e.g., 'cpu_usage', 'mem_usage', 'joules_usage').\n",
    "    :param title: Title of the plot.\n",
    "    :param xlabel: Label for the x-axis.\n",
    "    :param ylabel: Label for the y-axis.\n",
    "    \"\"\"\n",
    "    if metric not in output_df.columns:\n",
    "        raise ValueError(f\"Metric '{metric}' not found in the DataFrame.\")\n",
    "    \n",
    "    # Aggregate data by pod\n",
    "    pod_metric_data = output_df.groupby('pod_name')[metric].sum().reset_index()\n",
    "\n",
    "    # Sort the data for a cleaner area plot\n",
    "    pod_metric_data = pod_metric_data.sort_values(by=metric, ascending=False)\n",
    "\n",
    "    # Plot the area chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.stackplot(pod_metric_data['pod_name'], pod_metric_data[metric], alpha=0.8, labels=[metric])\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "baa461feb47a381a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T15:00:22.070846Z",
     "start_time": "2024-12-09T15:00:21.871126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from kfp import Client\n",
    "\n",
    "# Call the function with a sample path\n",
    "output_df = get_pipelines_cpu_memory_usage_per_pod(\"../data/pipeline_config_sample.yaml\")\n",
    "\n",
    "#display(output_df)  # Jupyter-friendly display\n",
    "\n",
    "# Access aggregated metrics\n",
    "print(output_df[['pipeline_name', 'total_cpu_usage', 'total_memory_usage', 'total_joules']])\n",
    "\n",
    "# Access per-pod metrics for a specific pipeline run\n",
    "print(output_df.iloc[0]['pod_metrics'])  # Per-pod metrics for the first run\n",
    "\n",
    "# Plot CPU usage per pod\n",
    "plot_area_per_pod(output_df, metric='cpu_usage', \n",
    "                  title='CPU Usage Distribution Among Pods', \n",
    "                  xlabel='Pod Names', ylabel='CPU Usage (cores)')\n",
    "\n",
    "# Plot Memory usage per pod\n",
    "plot_area_per_pod(output_df, metric='mem_usage', \n",
    "                  title='Memory Usage Distribution Among Pods', \n",
    "                  xlabel='Pod Names', ylabel='Memory Usage (MB)')\n",
    "\n",
    "# Plot Energy usage per pod\n",
    "plot_area_per_pod(output_df, metric='joules_usage', \n",
    "                  title='Energy Consumption Distribution Among Pods', \n",
    "                  xlabel='Pod Names', ylabel='Energy Consumption (Joules)')\n",
    "\n"
   ],
   "id": "3845af496e722183",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline size: 2\n",
      "Processing pipeline: chain_employee_data_pipeline_618e4a19-530b-405b-9ce6-a1f7788b9778\n",
      "Processing pipeline: chain_sales_data_pipeline_764bd130-0123-4a60-9f4e-31ff2b14b47f\n",
      "                                       pipeline_name  total_cpu_usage  \\\n",
      "0  chain_employee_data_pipeline_618e4a19-530b-405...              0.0   \n",
      "1  chain_employee_data_pipeline_618e4a19-530b-405...              0.0   \n",
      "2  chain_sales_data_pipeline_764bd130-0123-4a60-9...              0.0   \n",
      "3  chain_sales_data_pipeline_764bd130-0123-4a60-9...              0.0   \n",
      "\n",
      "   total_memory_usage  total_joules  \n",
      "0                 0.0           0.0  \n",
      "1                 0.0           0.0  \n",
      "2                 0.0           0.0  \n",
      "3                 0.0           0.0  \n",
      "Empty DataFrame\n",
      "Columns: [pod_name, cpu_usage, mem_usage, joules_usage, pipeline_name, pipeline_id, run_id]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Metric 'cpu_usage' not found in the DataFrame.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 19\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(output_df\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpod_metrics\u001B[39m\u001B[38;5;124m'\u001B[39m])  \u001B[38;5;66;03m# Per-pod metrics for the first run\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Plot CPU usage per pod\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m plot_area_per_pod(output_df, metric\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu_usage\u001B[39m\u001B[38;5;124m'\u001B[39m, \n\u001B[1;32m     20\u001B[0m                   title\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCPU Usage Distribution Among Pods\u001B[39m\u001B[38;5;124m'\u001B[39m, \n\u001B[1;32m     21\u001B[0m                   xlabel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPod Names\u001B[39m\u001B[38;5;124m'\u001B[39m, ylabel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCPU Usage (cores)\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Plot Memory usage per pod\u001B[39;00m\n\u001B[1;32m     24\u001B[0m plot_area_per_pod(output_df, metric\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmem_usage\u001B[39m\u001B[38;5;124m'\u001B[39m, \n\u001B[1;32m     25\u001B[0m                   title\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMemory Usage Distribution Among Pods\u001B[39m\u001B[38;5;124m'\u001B[39m, \n\u001B[1;32m     26\u001B[0m                   xlabel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPod Names\u001B[39m\u001B[38;5;124m'\u001B[39m, ylabel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMemory Usage (MB)\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[15], line 17\u001B[0m, in \u001B[0;36mplot_area_per_pod\u001B[0;34m(output_df, metric, title, xlabel, ylabel)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03mPlot an area chart for the given metric in the pipeline's per-pod usage data.\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m:param ylabel: Label for the y-axis.\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m metric \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m output_df\u001B[38;5;241m.\u001B[39mcolumns:\n\u001B[0;32m---> 17\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMetric \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m not found in the DataFrame.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Aggregate data by pod\u001B[39;00m\n\u001B[1;32m     20\u001B[0m pod_metric_data \u001B[38;5;241m=\u001B[39m output_df\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpod_name\u001B[39m\u001B[38;5;124m'\u001B[39m)[metric]\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39mreset_index()\n",
      "\u001B[0;31mValueError\u001B[0m: Metric 'cpu_usage' not found in the DataFrame."
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## test\n",
    "\n",
    "from prometheus_api_client import PrometheusConnect\n",
    "\n",
    "# Connect to your Prometheus instance\n",
    "prom = PrometheusConnect(url=\"http://localhost:9090\", disable_ssl=True)\n",
    "\n",
    "# Define your namespace\n",
    "namespace = \"kubeflow\"\n",
    "\n",
    "# Query to get the total energy consumption over the last 5 days\n",
    "#query = f'sum(sum_over_time(kepler_container_bpf_block_irq_total{{namespace=\"{namespace}\"}}[5d]))'\n",
    "query = f'kepler_container_bpf_block_irq_total{{namespace=\"{namespace}\"}}'\n",
    "\n",
    "# Execute the query\n",
    "result = prom.custom_query(query)\n",
    "\n",
    "# Extract and print the CPU consumption for each pod\n",
    "cpu_consumption = {item['metric']['pod']: float(item['value'][1]) for item in result if 'pod' in item['metric']}\n",
    "\n",
    "print(\"CPU consumption (in joules) of all pods in namespace\", namespace, \":\", cpu_consumption)\n",
    "\n"
   ],
   "id": "b55ed1703ca32a68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T10:02:34.656456Z",
     "start_time": "2024-12-10T10:02:34.637713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Define Prometheus query\n",
    "prometheus_url = \"http://localhost:9090/api/v1/query\"\n",
    "namespace = \"kubeflow\"  # Replace with your namespace\n",
    "query = '{namespace=\"' + namespace + '\", pod=\"chain-employee-data-pipeline-618e4a19-530b-405b-9ce6-a1f77gbfj9-system-container-impl-361845380\"}'\n",
    "#__name__=\"kepler.*\", \n",
    "# Send the query to Prometheus\n",
    "response = requests.get(prometheus_url, params={\"query\": query})\n",
    "\n",
    "if response.status_code == 200:\n",
    "    results = response.json()['data']['result']\n",
    "    \n",
    "    # Process and display results as a DataFrame\n",
    "    if results:\n",
    "        data = []\n",
    "        for item in results:\n",
    "            metric_name = item['metric'].get('__name__', 'unknown')\n",
    "            pod_name = item['metric'].get('pod', 'N/A')  # Get pod name\n",
    "            namespace_name = item['metric'].get('namespace', 'N/A')  # Get namespace name\n",
    "            value = item['value'][1]\n",
    "            data.append({\n",
    "                \"metric\": metric_name,\n",
    "                \"namespace\": namespace_name,\n",
    "                \"pod\": pod_name,\n",
    "                \"value\": value\n",
    "            })\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        print(\"Metrics with values > 0 from namespace '{}'\".format(namespace))\n",
    "        display(df)\n",
    "    else:\n",
    "        print(\"No metrics found matching the criteria.\")\n",
    "else:\n",
    "    print(f\"Error querying Prometheus: {response.status_code}\")\n"
   ],
   "id": "171d5b30d7ace797",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics with values > 0 from namespace 'kubeflow'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                               metric namespace  \\\n",
       "0            kube_pod_completion_time  kubeflow   \n",
       "1             kube_pod_container_info  kubeflow   \n",
       "2             kube_pod_container_info  kubeflow   \n",
       "3    kube_pod_container_state_started  kubeflow   \n",
       "4    kube_pod_container_state_started  kubeflow   \n",
       "..                                ...       ...   \n",
       "62               kube_pod_tolerations  kubeflow   \n",
       "63               kube_pod_tolerations  kubeflow   \n",
       "64           kube_pod_service_account  kubeflow   \n",
       "65                 kube_pod_scheduler  kubeflow   \n",
       "66  node_namespace_pod:kube_pod_info:  kubeflow   \n",
       "\n",
       "                                                  pod       value  \n",
       "0   chain-employee-data-pipeline-618e4a19-530b-405...  1733752305  \n",
       "1   chain-employee-data-pipeline-618e4a19-530b-405...           1  \n",
       "2   chain-employee-data-pipeline-618e4a19-530b-405...           1  \n",
       "3   chain-employee-data-pipeline-618e4a19-530b-405...  1733752294  \n",
       "4   chain-employee-data-pipeline-618e4a19-530b-405...  1733752294  \n",
       "..                                                ...         ...  \n",
       "62  chain-employee-data-pipeline-618e4a19-530b-405...           1  \n",
       "63  chain-employee-data-pipeline-618e4a19-530b-405...           1  \n",
       "64  chain-employee-data-pipeline-618e4a19-530b-405...           1  \n",
       "65  chain-employee-data-pipeline-618e4a19-530b-405...           1  \n",
       "66  chain-employee-data-pipeline-618e4a19-530b-405...           1  \n",
       "\n",
       "[67 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>namespace</th>\n",
       "      <th>pod</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kube_pod_completion_time</td>\n",
       "      <td>kubeflow</td>\n",
       "      <td>chain-employee-data-pipeline-618e4a19-530b-405...</td>\n",
       "      <td>1733752305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kube_pod_container_info</td>\n",
       "      <td>kubeflow</td>\n",
       "      <td>chain-employee-data-pipeline-618e4a19-530b-405...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kube_pod_container_info</td>\n",
       "      <td>kubeflow</td>\n",
       "      <td>chain-employee-data-pipeline-618e4a19-530b-405...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kube_pod_container_state_started</td>\n",
       "      <td>kubeflow</td>\n",
       "      <td>chain-employee-data-pipeline-618e4a19-530b-405...</td>\n",
       "      <td>1733752294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kube_pod_container_state_started</td>\n",
       "      <td>kubeflow</td>\n",
       "      <td>chain-employee-data-pipeline-618e4a19-530b-405...</td>\n",
       "      <td>1733752294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>kube_pod_tolerations</td>\n",
       "      <td>kubeflow</td>\n",
       "      <td>chain-employee-data-pipeline-618e4a19-530b-405...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>kube_pod_tolerations</td>\n",
       "      <td>kubeflow</td>\n",
       "      <td>chain-employee-data-pipeline-618e4a19-530b-405...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>kube_pod_service_account</td>\n",
       "      <td>kubeflow</td>\n",
       "      <td>chain-employee-data-pipeline-618e4a19-530b-405...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>kube_pod_scheduler</td>\n",
       "      <td>kubeflow</td>\n",
       "      <td>chain-employee-data-pipeline-618e4a19-530b-405...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>node_namespace_pod:kube_pod_info:</td>\n",
       "      <td>kubeflow</td>\n",
       "      <td>chain-employee-data-pipeline-618e4a19-530b-405...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T10:12:47.686178Z",
     "start_time": "2024-12-10T10:12:47.629762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Define Prometheus query\n",
    "prometheus_url = \"http://localhost:9090/api/v1/query\"\n",
    "namespace = \"kubeflow\"  # Replace with your namespace\n",
    "query = '{namespace=\"' + namespace + '\", pod=\"chain-employee-data-pipeline-618e4a19-530b-405b-9ce6-a1f77gbfj9-system-container-impl-361845380\"}'\n",
    "\n",
    "# Send the query to Prometheus\n",
    "response = requests.get(prometheus_url, params={\"query\": query})\n",
    "\n",
    "if response.status_code == 200:\n",
    "    results = response.json()['data']['result']\n",
    "    \n",
    "    # Process and display results as a DataFrame\n",
    "    if results:\n",
    "        data = []\n",
    "        for item in results:\n",
    "            metric_name = item['metric'].get('__name__', 'unknown')\n",
    "            pod_name = item['metric'].get('pod', 'N/A')  # Get pod name\n",
    "            namespace_name = item['metric'].get('namespace', 'N/A')  # Get namespace name\n",
    "            value = item['value'][1]\n",
    "            data.append({\n",
    "                \"metric\": metric_name,\n",
    "                \"namespace\": namespace_name,\n",
    "                \"pod\": pod_name,\n",
    "                \"value\": value\n",
    "            })\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        print(\"Metrics with values > 0 from namespace '{}'\".format(namespace))\n",
    "        print(df)\n",
    "\n",
    "        # Save DataFrame to a CSV file\n",
    "        output_file = \"prometheus_metrics.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Data successfully saved to '{output_file}'\")\n",
    "    else:\n",
    "        print(\"No metrics found matching the criteria.\")\n",
    "else:\n",
    "    print(f\"Error querying Prometheus: {response.status_code}\")\n"
   ],
   "id": "546cd7cf9d02ff7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics with values > 0 from namespace 'kubeflow'\n",
      "                               metric namespace  \\\n",
      "0            kube_pod_completion_time  kubeflow   \n",
      "1             kube_pod_container_info  kubeflow   \n",
      "2             kube_pod_container_info  kubeflow   \n",
      "3    kube_pod_container_state_started  kubeflow   \n",
      "4    kube_pod_container_state_started  kubeflow   \n",
      "..                                ...       ...   \n",
      "62               kube_pod_tolerations  kubeflow   \n",
      "63               kube_pod_tolerations  kubeflow   \n",
      "64           kube_pod_service_account  kubeflow   \n",
      "65                 kube_pod_scheduler  kubeflow   \n",
      "66  node_namespace_pod:kube_pod_info:  kubeflow   \n",
      "\n",
      "                                                  pod       value  \n",
      "0   chain-employee-data-pipeline-618e4a19-530b-405...  1733752305  \n",
      "1   chain-employee-data-pipeline-618e4a19-530b-405...           1  \n",
      "2   chain-employee-data-pipeline-618e4a19-530b-405...           1  \n",
      "3   chain-employee-data-pipeline-618e4a19-530b-405...  1733752294  \n",
      "4   chain-employee-data-pipeline-618e4a19-530b-405...  1733752294  \n",
      "..                                                ...         ...  \n",
      "62  chain-employee-data-pipeline-618e4a19-530b-405...           1  \n",
      "63  chain-employee-data-pipeline-618e4a19-530b-405...           1  \n",
      "64  chain-employee-data-pipeline-618e4a19-530b-405...           1  \n",
      "65  chain-employee-data-pipeline-618e4a19-530b-405...           1  \n",
      "66  chain-employee-data-pipeline-618e4a19-530b-405...           1  \n",
      "\n",
      "[67 rows x 4 columns]\n",
      "Data successfully saved to 'prometheus_metrics.csv'\n"
     ]
    }
   ],
   "execution_count": 46
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
